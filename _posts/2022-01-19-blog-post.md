---
title: 'Recommendation Systems'
date: 2022-01-19
permalink: /posts/recommendation_systems/
tags:
  - Recommendation Systems
  - Collaborative Filtering
  - Content-based Recommendation
---

Notes from the Recommendation Systems course by Prof. Arpit Rana @ DAIICT and the MMD course @ Stanford.

### Generating explanation for recommendations
![](https://i.imgur.com/4xEXV0N.png)


### 1. Recommendation as Rating Prediction

![](https://i.imgur.com/6yHKcsr.png)

#### a. Memory-based (Neighbour-based) methods
##### a.1 User User Collaborative Filtering
* Predict rating of a user for an item based on how the users peer rated it.
* So first, find neighbours of u2. One simple way could be construct vector from ratings on items that are rated by both the users, and compute the cosine sim of two vectors. Then find neighbours based on cosine sim.
![](https://i.imgur.com/g5AmImV.png)
* Also note that we can use XNOR (not jaccard) to compute similarity. As here, the 0 value represents dislike. So we might want to consider if both users dislike the same item, then they might be somewhat similar in a local view.
* For any user, we can either say that we will pick top-100 users as neighbours (k-Nearest Neighbours), or we can set a threshold and say that any user with similarity greater than thresh k would be a neighbour to the target user. 
* Now, once we have similar neighbours, we can do one of the following:
    1. Take average (or weighted average) rating of all user rating for items $i_x$ (with unknown item rating).
    Simple average of ratings:
    ![](https://i.imgur.com/ZhA2EbT.png)
    Weighted average based on user-user sim:
    ![](https://i.imgur.com/RjIJltC.png)
    An issue with this is that the ratings are subjective, i.e. for the same level of appreciation people may give different ratings. The difference in expression of appreciation is different for the same level of appreciation, and this is not captured here.
    2. Normalized rating for users
    ![](https://i.imgur.com/804HmQ7.png)


* **Similarity** 
![](https://i.imgur.com/h5yTegk.png)
![](https://i.imgur.com/2JZy5V1.png)

#### b. Model-based methods

### 2. Recommendation as a User-Based Classification Problem
![](https://i.imgur.com/1GLku2k.png)
We count how many neighbours have given each of the rating values. But now instead of counting each as 1, we multiply it with the user similarity, i.e. delta is 1 and is multiplied by user similarity weight. Then predict the rating which is given by the maximum number of neighbours.
* In short, this calculates the average sum of user similarity for each rating r if a user has given rating r to the item.
![](https://i.imgur.com/y8SZaoD.png)

* Extremes are better handled (i.e the recommendation is less risky) by regression than classification. E.g.: neighbour ratings 1, 5 will have 3 in regresion vs 1/5 in cls. So when the neighbour size is large, the risk can be minimized via regression more efficiently.


##### a.2 Item Item Collaborative Filtering
![](https://i.imgur.com/kVfyFLj.png)

##### a.3 User-User vs Item-Item Collaborative Filtering
The following criteria need to be considered while choosing one of the techniques:
1. **Accuracy:** A small number of high-confidence neighbors is far preferable than a large number of loosely coupled neighbors. Consider if #users>>#items (item-item, e.g. Amazon) or #items>>#users (user-user, e.g. research article recommendation).
2. **Efficiency:** Ratio of number of users and items.
3. **Stability:** Frequency and amount of change in the users and items of the system. E.g. if items are constantly changing (like research papers) then user-user is prefereable. If the list of users are updating and the list of items is fairly static, item based approach is preferable, e.g. online shopping applications.
4. **Justifiability:** Depends on the explainability of reco approach. The list of neighboring items is more justifiable than the list of users (most users are unknown to the active user).
5. **Serendipity:** depends on the ability of the recommendation approach to offer surprising recommendations. tem based approach relies on items similar to active users items; thus, less prone to provide more surprising recommendations. User based approach relies on peersâ€™ opinio with similar tastes. In case, a user likes one item different from her usual taste, may be recommended to her peers.

##### a.4 Components of Memory-based (Neighbour-based) methods
![](https://i.imgur.com/XgiVeBD.png)
1. **Rating Normalization:** Mean-centering, Z-score. Mean-centering determine if the rating is + or - with repect to the users mean rating. Z-score also considers the spread in an individual's rating scale.
![](https://i.imgur.com/oCRo9B5.png)
![](https://i.imgur.com/eJDCzQF.png)
Mean-centering vs Z-score
![](https://i.imgur.com/6jdNyi9.png)

2. **Computataion of Similarity Weights:**
![](https://i.imgur.com/vscbrqw.png)
E.g.: Cosine Vector similarity, Pearon correlation, Adjusted Cosine
![](https://i.imgur.com/B67hx5X.png)
![](https://i.imgur.com/WGRoItp.png)
![](https://i.imgur.com/cmSL8sa.png)
In above, note the significance of Adjusted cosine in item-based setting, i.e. the similarity between items i and j. $U_{ij}$ is the set of all users that have rated both items i and j.

![](https://i.imgur.com/SAc6voU.png)
![](https://i.imgur.com/0kP7GWx.png)
![](https://i.imgur.com/lGimdgj.png)

3. **Selecting Neighbors**
![](https://i.imgur.com/mvbp89b.png)


## Content Based Approaches
![](https://i.imgur.com/udqtEij.png)



# From Stanford MMD:
![](https://i.imgur.com/Xbr97F3.png)
![](https://i.imgur.com/JTAPEm7.png)

http://snap.stanford.edu/class/cs246-2015/slides/07-recsys1.pdf